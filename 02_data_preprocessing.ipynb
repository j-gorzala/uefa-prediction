{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "pd.set_option('display.max_columns', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(os.getcwd(), 'data')\n",
    "data_files = os.listdir(data_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge fbref files into single dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fbref_teams_df = pd.read_csv('data/fbref_team_season_stats_standard.csv', sep=';', index_col=0)[['league', 'season', 'team']].drop_duplicates()\n",
    "\n",
    "for f in [_ for _ in data_files if _.startswith('fbref')]:\n",
    "    fbref_df = pd.read_csv(os.path.join(data_path, f), sep=';', index_col=0)\n",
    "    try:\n",
    "        fbref_df = fbref_df.drop(columns=['url', '#_Pl'])\n",
    "    except:\n",
    "        pass\n",
    "    duplicated_cols = [col for col in fbref_df.columns if col in fbref_teams_df.columns and col not in ['team', 'league', 'season']]\n",
    "    \n",
    "    if len(duplicated_cols) > 0:\n",
    "        fbref_df = fbref_df.drop(columns=duplicated_cols)\n",
    "    \n",
    "    fbref_teams_df = fbref_teams_df.merge(fbref_df, how='inner', on=['team', 'league', 'season'])\n",
    "\n",
    "fbref_teams_df.to_csv(f'data_preprocessed/fbref_team_aggregates.csv', sep=';')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide match_history_data into home and away data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_history_data = pd.read_csv('data/match_history_data.csv', sep=';', index_col=0).reset_index(drop=True)\n",
    "match_history_data['Match_Date'] = pd.to_datetime(match_history_data['Match_Date'])\n",
    "\n",
    "# Filter to played matches\n",
    "match_history_data = match_history_data[match_history_data['Match_Date'] < datetime.now()]\n",
    "\n",
    "# Create match_id\n",
    "match_history_data['match_id'] = np.arange(1, match_history_data.shape[0] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_team_match_data = match_history_data[\n",
    "    [\n",
    "        'match_id', 'league', 'season', 'Match_Date', 'Home_Team', 'Bet365_home_win_odds', 'Bet365_draw_odds'\n",
    "    ]\n",
    "]\n",
    "\n",
    "\n",
    "away_team_match_data = match_history_data[\n",
    "    [\n",
    "        'match_id', 'league', 'season', 'Match_Date', 'Away_Team', 'Bet365_away_win_odds', 'Bet365_draw_odds'\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge ELO scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "elo_scores = pd.read_csv('data/elo_scores.csv', sep=';', index_col=0).reset_index(drop=True).drop(columns=['rank', 'country', 'level', 'league'])\n",
    "elo_scores['from'] = pd.to_datetime(elo_scores['from'])\n",
    "elo_scores['to'] = pd.to_datetime(elo_scores['to'])\n",
    "elo_scores = elo_scores.rename(columns={'from': 'start', 'to': 'end'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the db in memory\n",
    "conn = sqlite3.connect(':memory:')\n",
    "\n",
    "# Write the tables\n",
    "home_team_match_data.to_sql('home_team_match_data', conn, index=False)\n",
    "away_team_match_data.to_sql('away_team_match_data', conn, index=False)\n",
    "elo_scores.to_sql('elo_scores', conn, index=False)\n",
    "\n",
    "sqlcode_home = '''\n",
    "select A.*, B.elo as elo\n",
    "from home_team_match_data A\n",
    "left join elo_scores B \n",
    "on A.Home_Team = B.team\n",
    "and A.Match_Date <= B.end\n",
    "order by A.match_id, A.Match_Date, B.end\n",
    "'''\n",
    "#  and A.Match_Date <= B.end\n",
    "sqlcode_away = '''\n",
    "select A.*, B.elo as elo\n",
    "from away_team_match_data A\n",
    "left join elo_scores B \n",
    "on A.Away_Team = B.team\n",
    "and A.Match_Date <= B.end\n",
    "order by A.match_id, A.Match_Date, B.end\n",
    "'''\n",
    "\n",
    "home_team_match_elo_data = pd.read_sql_query(sqlcode_home, conn).groupby('match_id').first().reset_index()\n",
    "away_team_match_elo_data = pd.read_sql_query(sqlcode_away, conn).groupby('match_id').first().reset_index()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge fbref_team_aggregates and fifa data to home and away data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "fifa_data = pd.read_csv('data/FIFA_data.csv', sep=';', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge data for home teams\n",
    "home_team_model_data = home_team_match_elo_data.merge(\n",
    "    fbref_teams_df, left_on=[\"season\", \"Home_Team\", \"league\"], right_on=[\"season\", \"team\", \"league\"], how=\"left\"\n",
    ").merge(\n",
    "    fifa_data, left_on=[\"season\", \"Home_Team\"], right_on=[\"season\", \"Club\"], how=\"left\"\n",
    ")\n",
    "\n",
    "# Merge data for away teams\n",
    "away_team_model_data = away_team_match_elo_data.merge(\n",
    "    fbref_teams_df, left_on=[\"season\", \"Away_Team\", \"league\"], right_on=[\"season\", \"team\", \"league\"], how=\"left\"\n",
    ").merge(\n",
    "    fifa_data, left_on=[\"season\", \"Away_Team\"], right_on=[\"season\", \"Club\"], how=\"left\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_team_model_data = home_team_model_data.drop(columns=['league', 'season', 'Match_Date', 'Home_Team', 'team', 'Club'])\n",
    "home_team_model_data = home_team_model_data[home_team_model_data[\"match_id\"].isin(away_team_model_data[\"match_id\"])].sort_values(\"match_id\").reset_index(drop=True)\n",
    "home_team_model_data.to_csv(\"data_preprocessed/home_team_model_data.csv\", sep=\";\")\n",
    "\n",
    "away_team_model_data = away_team_model_data.drop(columns=['league', 'season', 'Match_Date', 'Away_Team', 'team', 'Club']).sort_values(\"match_id\")\n",
    "away_team_model_data = away_team_model_data[away_team_model_data[\"match_id\"].isin(home_team_model_data[\"match_id\"])].sort_values(\"match_id\").reset_index(drop=True)\n",
    "away_team_model_data.to_csv(\"data_preprocessed/away_team_model_data.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Home to away\n",
    "home_to_away_model_data = pd.concat([home_team_model_data[[\"match_id\", \"Bet365_home_win_odds\", \"Bet365_draw_odds\"]], home_team_model_data.drop(columns=[\"match_id\", \"Bet365_home_win_odds\", \"Bet365_draw_odds\"]) / away_team_model_data.drop(columns=[\"match_id\", \"Bet365_away_win_odds\", \"Bet365_draw_odds\"])], axis=1)\n",
    "home_to_away_model_data[\"match_id\"] = home_to_away_model_data[\"match_id\"].map(lambda x: \"home_\" + str(x))\n",
    "\n",
    "# Away to home\n",
    "away_to_home_model_data = pd.concat([away_team_model_data[[\"match_id\", \"Bet365_away_win_odds\", \"Bet365_draw_odds\"]], away_team_model_data.drop(columns=[\"match_id\", \"Bet365_away_win_odds\", \"Bet365_draw_odds\"]) / home_team_model_data.drop(columns=[\"match_id\", \"Bet365_home_win_odds\", \"Bet365_draw_odds\"])], axis=1)\n",
    "away_to_home_model_data[\"match_id\"] = away_to_home_model_data[\"match_id\"].map(lambda x: \"away_\" + str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_to_away_model_data.to_csv(\"data_preprocessed/home_to_away_model_data.csv\", sep=\";\")\n",
    "away_to_home_model_data.to_csv(\"data_preprocessed/away_to_home_model_data.csv\", sep=\";\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_history_data.to_csv(\"data_preprocessed/sample_matches.csv\", sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kubag\\AppData\\Local\\Temp/ipykernel_8292/2408851681.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  home_match_history_data[\"match_id\"] = home_match_history_data[\"match_id\"].map(lambda x: \"home_\" + str(x))\n",
      "C:\\Users\\kubag\\AppData\\Local\\Temp/ipykernel_8292/2408851681.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  away_match_history_data[\"match_id\"] = away_match_history_data[\"match_id\"].map(lambda x: \"away_\" + str(x))\n"
     ]
    }
   ],
   "source": [
    "home_match_history_data = match_history_data[['match_id', 'Full_Time_Home_Team_Goals', 'Home_Team_Shots_on_Target', 'Result_Home_Team_Win', 'Result_Draw']]\n",
    "home_match_history_data[\"match_id\"] = home_match_history_data[\"match_id\"].map(lambda x: \"home_\" + str(x))\n",
    "\n",
    "away_match_history_data = match_history_data[['match_id', 'Full_Time_Away_Team_Goals', 'Away_Team_Shots_on_Target', 'Result_Away_Team_Win', 'Result_Draw']]\n",
    "away_match_history_data[\"match_id\"] = away_match_history_data[\"match_id\"].map(lambda x: \"away_\" + str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_match_history_data.to_csv(\"data_preprocessed/home_match_history_data.csv\", sep=';')\n",
    "away_match_history_data.to_csv(\"data_preprocessed/away_match_history_data.csv\", sep=';')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scraping_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
